{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Assignment5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/piyushjain220/TSAI/blob/main/NLP/Session5/Assignment5-1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jofyc9OC4Qcf"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahBVnrNc3E0U"
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "plt.style.use('seaborn-white')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crQSAaIz4SkA"
      },
      "source": [
        "# Read and process data. \n",
        "\n",
        "Download the file from this URL: https://drive.google.com/file/d/1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgOGxPDP3Wpp"
      },
      "source": [
        "data = open('text.txt', 'r').read()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeXXMLRb4kXb"
      },
      "source": [
        "Process data and calculate indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5TKeiOp4jtl",
        "outputId": "de6a0cc2-d996-4806-de5a-2b61091c0841"
      },
      "source": [
        "chars = list(set(data))\n",
        "data_size, X_size = len(data), len(chars)\n",
        "print(\"Corona Virus article has %d characters, %d unique characters\" %(data_size, X_size))\n",
        "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
        "idx_to_char = {i:ch for i,ch in enumerate(chars)}"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corona Virus article has 10223 characters, 75 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C53MB135LRY"
      },
      "source": [
        "# Constants and Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfj21ORa49Ps"
      },
      "source": [
        "Hidden_Layer_size = 100 #size of the hidden layer\n",
        "Time_steps = 40 # Number of time steps (length of the sequence) used for training\n",
        "learning_rate = 1e-1 # Learning Rate\n",
        "weight_sd = 0.1 #Standard deviation of weights for initialization\n",
        "z_size = Hidden_Layer_size + X_size #Size of concatenation(H, X) vector"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdmJf4Du5uhb"
      },
      "source": [
        "# Activation Functions and Derivatives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeCvVH1v6Me-"
      },
      "source": [
        "# Quiz Question 1\n",
        "\n",
        "What is the value of sigmoid(0) calculated from  your code? (Answer up to 1 decimal point, e.g. 4.2 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "Answer: 0.5\n",
        "\n",
        "# Quiz Question 2\n",
        "\n",
        "What is the value of dsigmoid(sigmoid(0)) calculated from your code?? (Answer up to 2 decimal point, e.g. 4.29 and NOT 4.29999999, no rounding off). \n",
        "\n",
        "Answer: 0.23\n",
        "\n",
        "# Quiz Question 3\n",
        "\n",
        "What is the value of tanh(dsigmoid(sigmoid(0))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "Answer: 0.23077\n",
        "\n",
        "# Quiz Question 4\n",
        "\n",
        "What is the value of dtanh(tanh(dsigmoid(sigmoid(0)))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "Answer: 0.94857"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seGHei_D5FGk"
      },
      "source": [
        "import numpy as np\n",
        "def sigmoid(x): # sigmoid function\n",
        "  return 1/(1 + np.exp(-x))            # write your code here\n",
        "\n",
        "def dsigmoid(y): # derivative of sigmoid function\n",
        "  return  y*(1-y)  # write your code here\n",
        "\n",
        "def tanh(x): # tanh function\n",
        "  return np.tanh(x)\n",
        "\n",
        "def dtanh(y): # derivative of tanh\n",
        "  return 1 - y*y # write your code here"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJLA6aZoDl4b",
        "outputId": "60e4bfc3-bf15-4bde-b308-f6beb68869f3"
      },
      "source": [
        "sigmoid(0)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eANUTwouD7mZ",
        "outputId": "4883299b-565c-4e8a-f79c-481307218d3b"
      },
      "source": [
        "dsigmoid(sigmoid(0))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cX6I7WhgEGGp",
        "outputId": "0bf6a826-b9b9-4cb9-da7b-6f446174201c"
      },
      "source": [
        "tanh(dsigmoid(sigmoid(0)))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.24491866240370913"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjNIA1wwEQVP",
        "outputId": "abfd7825-9d8a-42ec-9049-e204b872d671"
      },
      "source": [
        "dtanh(tanh(dsigmoid(sigmoid(0))))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.940014848806378"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeSVipDu8iKE"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICbWNemE6LGV"
      },
      "source": [
        "class Param:\n",
        "    def __init__(self, name, value):\n",
        "      self.name = name\n",
        "      self.v = value # parameter value\n",
        "      self.d = np.zeros_like(value) # derivative\n",
        "      self.m = np.zeros_like(value) # momentum for Adagrad"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j83pZNPE8212"
      },
      "source": [
        "We use random weights with normal distribution (0, weight_sd) for  tanh  activation function and (0.5, weight_sd) for  `sigmoid`  activation function.\n",
        "\n",
        "Biases are initialized to zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0DBzNY-90s5"
      },
      "source": [
        "# Quiz Question 5\n",
        "\n",
        "In the class definition below, what should be size_a, size_b, and size_c? ONLY use the variables defined above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swHwLXOI9E7V"
      },
      "source": [
        "# LSTM \n",
        "You are making this network, please note f, i, c and o (also \"v\") in the image below:\n",
        "![alt text](http://blog.varunajayasiri.com/ml/lstm.svg)\n",
        "\n",
        "Please note that we are concatenating the old_hidden_vector and new_input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFuHhqVq6Wge"
      },
      "source": [
        "size_a = Hidden_Layer_size# write your code here\n",
        "size_b = z_size # write your code here\n",
        "size_c = X_size # write your code here\n",
        "\n",
        "class Parameters:\n",
        "    def __init__(self):\n",
        "        self.W_f = Param('W_f', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_f = Param('b_f', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_i = Param('W_i', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_i = Param('b_i', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_C = Param('W_C', np.random.randn(size_a, size_b) * weight_sd)\n",
        "        self.b_C = Param('b_C', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_o = Param('W_o', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_o = Param('b_o', np.zeros((size_a, 1)))\n",
        "\n",
        "        #For final layer to predict the next character\n",
        "        self.W_v = Param('W_v', np.random.randn(X_size, size_a) * weight_sd)\n",
        "        self.b_v = Param('b_v', np.zeros((size_c, 1)))\n",
        "        \n",
        "    def all(self):\n",
        "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
        "               self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
        "        \n",
        "parameters = Parameters()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzmfGLZt_xVs"
      },
      "source": [
        "Look at these operations which we'll be writing:\n",
        "\n",
        "**Concatenation of h and x:**\n",
        "\n",
        "$z\\:=\\:\\left[h_{t-1},\\:x\\right]$\n",
        "\n",
        "$f_t=\\sigma\\left(W_f\\cdot z\\:+\\:b_f\\:\\right)$\n",
        "\n",
        "$i_i=\\sigma\\left(W_i\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$\\overline{C_t}=\\tanh\\left(W_C\\cdot z\\:+\\:b_C\\right)$\n",
        "\n",
        "$C_t=f_t\\ast C_{t-1}+i_t\\ast \\overline{C}_t$\n",
        "\n",
        "$o_t=\\sigma\\left(W_o\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$h_t=o_t\\ast\\tanh\\left(C_t\\right)$\n",
        "\n",
        "**Logits:**\n",
        "\n",
        "$v_t=W_v\\cdot h_t+b_v$\n",
        "\n",
        "**Softmax:**\n",
        "\n",
        "$\\hat{y}=softmax\\left(v_t\\right)$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bUkseNnDott"
      },
      "source": [
        "def forward(x, h_prev, C_prev, p = parameters):\n",
        "    assert x.shape == (X_size, 1)\n",
        "    assert h_prev.shape == (Hidden_Layer_size, 1)\n",
        "    assert C_prev.shape == (Hidden_Layer_size, 1)\n",
        "    \n",
        "    z = np.row_stack((h_prev, x))\n",
        "    f = sigmoid(np.dot(p.W_f.v, z) + p.b_f.v)   # write your code here\n",
        "    i = sigmoid(np.dot(p.W_i.v, z) + p.b_i.v) # write your code here\n",
        "    C_bar = tanh(np.dot(p.W_C.v, z) + p.b_C.v)   # write your code here\n",
        "\n",
        "    C = f*C_prev + i*C_bar # write your code here\n",
        "    o = sigmoid(np.dot(p.W_o.v, z) + p.b_o.v) # write your code here\n",
        "    h = o * tanh(C) # write your code here\n",
        "\n",
        "    v =  np.dot(p.W_v.v, h) +  p.b_v.v   # write your code here\n",
        "    y = np.exp(v) / np.sum(np.exp(v)) #softmax\n",
        "\n",
        "    return z, f, i, C_bar, C, o, h, v, y"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZrDhZIjFpdI"
      },
      "source": [
        "You must finish the function above before you can attempt the questions below. \n",
        "\n",
        "# Quiz Question 6\n",
        "\n",
        "What is the output of 'print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))'?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3loq2GvMhGSA",
        "outputId": "3b9eedb7-3624-4d4b-e94a-c7ddb6a3b13e"
      },
      "source": [
        "print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV-YVl_GGiX8"
      },
      "source": [
        "# Quiz Question 7. \n",
        "\n",
        "Assuming you have fixed the forward function, run this command: \n",
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))\n",
        "\n",
        "Now, find these values:\n",
        "\n",
        "\n",
        "1.   print(z.shape)\n",
        "2.   print(np.sum(z))\n",
        "3.   print(np.sum(f))\n",
        "\n",
        "Copy and paste exact values you get in the logs into the quiz.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvKVWmTDt3H"
      },
      "source": [
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huRUmmQ2AS-L",
        "outputId": "78ec4ee2-c64d-47b3-dce1-0b727ce98725"
      },
      "source": [
        "print(z.shape)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(175, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWvnCoLKAinF",
        "outputId": "44b70070-0821-44ab-eaaa-1c02a58ee852"
      },
      "source": [
        "print(np.sum(z))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ev_yKFNNApQy",
        "outputId": "37bcaa73-b452-452f-f6a5-0fe02d7df9e8"
      },
      "source": [
        "print(np.sum(f))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeSvhkqwILsG"
      },
      "source": [
        "# Backpropagation\n",
        "\n",
        "Here we are defining the backpropagation. It's too complicated, here is the whole code. (Please note that this would work only if your earlier code is perfect)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIa1jUZiGPmF"
      },
      "source": [
        "def backward(target, dh_next, dC_next, C_prev,\n",
        "             z, f, i, C_bar, C, o, h, v, y,\n",
        "             p = parameters):\n",
        "    \n",
        "    assert z.shape == (X_size + Hidden_Layer_size, 1)\n",
        "    assert v.shape == (X_size, 1)\n",
        "    assert y.shape == (X_size, 1)\n",
        "    \n",
        "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
        "        assert param.shape == (Hidden_Layer_size, 1)\n",
        "        \n",
        "    dv = np.copy(y)\n",
        "    dv[target] -= 1\n",
        "\n",
        "    p.W_v.d += np.dot(dv, h.T)\n",
        "    p.b_v.d += dv\n",
        "\n",
        "    dh = np.dot(p.W_v.v.T, dv)        \n",
        "    dh += dh_next\n",
        "    do = dh * tanh(C)\n",
        "    do = dsigmoid(o) * do\n",
        "    p.W_o.d += np.dot(do, z.T)\n",
        "    p.b_o.d += do\n",
        "\n",
        "    dC = np.copy(dC_next)\n",
        "    dC += dh * o * dtanh(tanh(C))\n",
        "    dC_bar = dC * i\n",
        "    dC_bar = dtanh(C_bar) * dC_bar\n",
        "    p.W_C.d += np.dot(dC_bar, z.T)\n",
        "    p.b_C.d += dC_bar\n",
        "\n",
        "    di = dC * C_bar\n",
        "    di = dsigmoid(i) * di\n",
        "    p.W_i.d += np.dot(di, z.T)\n",
        "    p.b_i.d += di\n",
        "\n",
        "    df = dC * C_prev\n",
        "    df = dsigmoid(f) * df\n",
        "    p.W_f.d += np.dot(df, z.T)\n",
        "    p.b_f.d += df\n",
        "\n",
        "    dz = (np.dot(p.W_f.v.T, df)\n",
        "         + np.dot(p.W_i.v.T, di)\n",
        "         + np.dot(p.W_C.v.T, dC_bar)\n",
        "         + np.dot(p.W_o.v.T, do))\n",
        "    dh_prev = dz[:Hidden_Layer_size, :]\n",
        "    dC_prev = f * dC\n",
        "    \n",
        "    return dh_prev, dC_prev"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnc7WpRkIU5S"
      },
      "source": [
        "# Forward and Backward Combined Pass\n",
        "\n",
        "Let's first clear the gradients before each backward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJWoC3U1ITf8"
      },
      "source": [
        "def clear_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.d.fill(0)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XN93UnjIgmA"
      },
      "source": [
        "Clip gradients to mitigate exploding gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LTsublxIfFl"
      },
      "source": [
        "def clip_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        np.clip(p.d, -1, 1, out=p.d)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7XUpDTWIl_Y"
      },
      "source": [
        "Calculate and store the values in forward pass. Accumulate gradients in backward pass and clip gradients to avoid exploding gradients.\n",
        "\n",
        "input, target are list of integers, with character indexes.\n",
        "h_prev is the array of initial h at  h−1  (size H x 1)\n",
        "C_prev is the array of initial C at  C−1  (size H x 1)\n",
        "Returns loss, final  hT  and  CT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQNxjTuZIia_"
      },
      "source": [
        "def forward_backward(inputs, targets, h_prev, C_prev):\n",
        "    global paramters\n",
        "    \n",
        "    # To store the values for each time step\n",
        "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
        "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
        "    v_s, y_s =  {}, {}\n",
        "    \n",
        "    # Values at t - 1\n",
        "    h_s[-1] = np.copy(h_prev)\n",
        "    C_s[-1] = np.copy(C_prev)\n",
        "    \n",
        "    loss = 0\n",
        "    # Loop through time steps\n",
        "    assert len(inputs) == Time_steps\n",
        "    for t in range(len(inputs)):\n",
        "        x_s[t] = np.zeros((X_size, 1))\n",
        "        x_s[t][inputs[t]] = 1 # Input character\n",
        "        \n",
        "        (z_s[t], f_s[t], i_s[t],\n",
        "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
        "        v_s[t], y_s[t]) = \\\n",
        "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
        "            \n",
        "        loss += -np.log(y_s[t][targets[t], 0]) # Loss for at t\n",
        "        \n",
        "    clear_gradients()\n",
        "\n",
        "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
        "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
        "\n",
        "    for t in reversed(range(len(inputs))):\n",
        "        # Backward pass\n",
        "        dh_next, dC_next = \\\n",
        "            backward(target = targets[t], dh_next = dh_next,\n",
        "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
        "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
        "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
        "                     y = y_s[t])\n",
        "\n",
        "    clip_gradients()\n",
        "        \n",
        "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcy5u_vRItkV"
      },
      "source": [
        "# Sample the next character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8SrtJiwIsSm"
      },
      "source": [
        "def sample(h_prev, C_prev, first_char_idx, sentence_length):\n",
        "    x = np.zeros((X_size, 1))\n",
        "    x[first_char_idx] = 1\n",
        "\n",
        "    h = h_prev\n",
        "    C = C_prev\n",
        "\n",
        "    indexes = []\n",
        "    \n",
        "    for t in range(sentence_length):\n",
        "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
        "        #idx = np.random.choice(range(X_size), p=p.ravel())\n",
        "        idx = np.random.choice(range(X_size))\n",
        "        x = np.zeros((X_size, 1))\n",
        "        x[idx] = 1\n",
        "        indexes.append(idx)\n",
        "\n",
        "    return indexes"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiWFaWLNIx_L"
      },
      "source": [
        "# Training (Adagrad)\n",
        "\n",
        "Update the graph and display a sample output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENQYU-7AIw0t"
      },
      "source": [
        "def update_status(inputs, h_prev, C_prev):\n",
        "    #initialized later\n",
        "    global plot_iter, plot_loss\n",
        "    global smooth_loss\n",
        "    \n",
        "    # Get predictions for 200 letters with current model\n",
        "\n",
        "    sample_idx = sample(h_prev, C_prev, inputs[0], 200)\n",
        "    txt = ''.join(idx_to_char[idx] for idx in sample_idx)\n",
        "\n",
        "    # Clear and plot\n",
        "    plt.plot(plot_iter, plot_loss)\n",
        "    display.clear_output(wait=True)\n",
        "    plt.show()\n",
        "\n",
        "    #Print prediction and loss\n",
        "    print(\"----\\n %s \\n----\" % (txt, ))\n",
        "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACXcASJuI73a"
      },
      "source": [
        "# Update Parameters\n",
        "\n",
        "\\begin{align}\n",
        "\\theta_i &= \\theta_i - \\eta\\frac{d\\theta_i}{\\sum dw_{\\tau}^2} \\\\\n",
        "d\\theta_i &= \\frac{\\partial L}{\\partial \\theta_i}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR08TvcjI4Pf"
      },
      "source": [
        "def update_paramters(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.m += p.d * p.d # Calculate sum of gradients\n",
        "        #print(learning_rate * dparam)\n",
        "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La9vyJ6RJLFK"
      },
      "source": [
        "To delay the keyboard interrupt to prevent the training from stopping in the middle of an iteration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVDHbMb7JNGT"
      },
      "source": [
        "# Exponential average of loss\n",
        "# Initialize to a error of a random model\n",
        "smooth_loss = -np.log(1.0 / X_size) * Time_steps\n",
        "\n",
        "iteration, pointer = 0, 0\n",
        "\n",
        "# For the graph\n",
        "plot_iter = np.zeros((0))\n",
        "plot_loss = np.zeros((0))"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF6vS0VWJqsS"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "OQyNSL0iJOxH",
        "outputId": "593588d1-d2ca-4705-96b7-0bd17e8a0378"
      },
      "source": [
        "iter = 50000\n",
        "while iter > 0:\n",
        "  # Reset\n",
        "  if pointer + Time_steps >= len(data) or iteration == 0:\n",
        "      g_h_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      g_C_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      pointer = 0\n",
        "\n",
        "\n",
        "  inputs = ([char_to_idx[ch] \n",
        "              for ch in data[pointer: pointer + Time_steps]])\n",
        "  targets = ([char_to_idx[ch] \n",
        "              for ch in data[pointer + 1: pointer + Time_steps + 1]])\n",
        "\n",
        "  loss, g_h_prev, g_C_prev = \\\n",
        "      forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
        "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "\n",
        "  # Print every hundred steps\n",
        "  if iteration % 100 == 0:\n",
        "      update_status(inputs, g_h_prev, g_C_prev)\n",
        "\n",
        "  update_paramters()\n",
        "\n",
        "  plot_iter = np.append(plot_iter, [iteration])\n",
        "  plot_loss = np.append(plot_loss, [loss])\n",
        "\n",
        "  pointer += Time_steps\n",
        "  iteration += 1\n",
        "  iter = iter -1"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "----\n",
            " 28–e9EkNFNyl)k59IL(TWh35\"wiuo1jaanIE9B)EK�WA1ysg–B6;dwkmKHL):hb“T'7hN8E,a7eU)V,gH,(0t1zFADiJ'ra?g’BECf.J\"4WNLc;q0R1?2ASzg“H8nnUnTDiOC2�CUla8S5RLkM)h.;,W–jYpS8GM:9b6yp yj27bg0mmP'J\"uC\n",
            "\n",
            "ih-Nbhl\"vH-Ia Wv \n",
            "----\n",
            "iter 99900, loss 2.035076\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AKpa1BGOItQ"
      },
      "source": [
        "# Quiz Question 8. \n",
        "\n",
        "Run the above code for 50000 iterations making sure that you have 100 hidden layers and time_steps is 40. What is the loss value you're seeing?"
      ]
    }
  ]
}