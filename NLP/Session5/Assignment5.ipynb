{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Assignment5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/piyushjain220/TSAI/blob/main/NLP/Session5/Assignment5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jofyc9OC4Qcf"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahBVnrNc3E0U"
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "plt.style.use('seaborn-white')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crQSAaIz4SkA"
      },
      "source": [
        "# Read and process data. \n",
        "\n",
        "Download the file from this URL: https://drive.google.com/file/d/1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgOGxPDP3Wpp"
      },
      "source": [
        "data = open('text.txt', 'r').read()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeXXMLRb4kXb"
      },
      "source": [
        "Process data and calculate indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5TKeiOp4jtl",
        "outputId": "de6a0cc2-d996-4806-de5a-2b61091c0841"
      },
      "source": [
        "chars = list(set(data))\n",
        "data_size, X_size = len(data), len(chars)\n",
        "print(\"Corona Virus article has %d characters, %d unique characters\" %(data_size, X_size))\n",
        "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
        "idx_to_char = {i:ch for i,ch in enumerate(chars)}"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corona Virus article has 10223 characters, 75 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C53MB135LRY"
      },
      "source": [
        "# Constants and Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfj21ORa49Ps"
      },
      "source": [
        "Hidden_Layer_size = 100 #size of the hidden layer\n",
        "Time_steps = 40 # Number of time steps (length of the sequence) used for training\n",
        "learning_rate = 1e-1 # Learning Rate\n",
        "weight_sd = 0.1 #Standard deviation of weights for initialization\n",
        "z_size = Hidden_Layer_size + X_size #Size of concatenation(H, X) vector"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdmJf4Du5uhb"
      },
      "source": [
        "# Activation Functions and Derivatives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeCvVH1v6Me-"
      },
      "source": [
        "# Quiz Question 1\n",
        "\n",
        "What is the value of sigmoid(0) calculated from  your code? (Answer up to 1 decimal point, e.g. 4.2 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "Answer: 0.5\n",
        "\n",
        "# Quiz Question 2\n",
        "\n",
        "What is the value of dsigmoid(sigmoid(0)) calculated from your code?? (Answer up to 2 decimal point, e.g. 4.29 and NOT 4.29999999, no rounding off). \n",
        "\n",
        "Answer: 0.23\n",
        "\n",
        "# Quiz Question 3\n",
        "\n",
        "What is the value of tanh(dsigmoid(sigmoid(0))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "Answer: 0.23077\n",
        "\n",
        "# Quiz Question 4\n",
        "\n",
        "What is the value of dtanh(tanh(dsigmoid(sigmoid(0)))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "Answer: 0.94857"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seGHei_D5FGk"
      },
      "source": [
        "import numpy as np\n",
        "def sigmoid(x): # sigmoid function\n",
        "  return 1/(1 + np.exp(-x))            # write your code here\n",
        "\n",
        "def dsigmoid(y): # derivative of sigmoid function\n",
        "  return  y*(1-y)  # write your code here\n",
        "\n",
        "def tanh(x): # tanh function\n",
        "  return np.tanh(x)\n",
        "\n",
        "def dtanh(y): # derivative of tanh\n",
        "  return 1 - y*y # write your code here"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJLA6aZoDl4b",
        "outputId": "60e4bfc3-bf15-4bde-b308-f6beb68869f3"
      },
      "source": [
        "sigmoid(0)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eANUTwouD7mZ",
        "outputId": "4883299b-565c-4e8a-f79c-481307218d3b"
      },
      "source": [
        "dsigmoid(sigmoid(0))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cX6I7WhgEGGp",
        "outputId": "0bf6a826-b9b9-4cb9-da7b-6f446174201c"
      },
      "source": [
        "tanh(dsigmoid(sigmoid(0)))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.24491866240370913"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjNIA1wwEQVP",
        "outputId": "abfd7825-9d8a-42ec-9049-e204b872d671"
      },
      "source": [
        "dtanh(tanh(dsigmoid(sigmoid(0))))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.940014848806378"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeSVipDu8iKE"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICbWNemE6LGV"
      },
      "source": [
        "class Param:\n",
        "    def __init__(self, name, value):\n",
        "      self.name = name\n",
        "      self.v = value # parameter value\n",
        "      self.d = np.zeros_like(value) # derivative\n",
        "      self.m = np.zeros_like(value) # momentum for Adagrad"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j83pZNPE8212"
      },
      "source": [
        "We use random weights with normal distribution (0, weight_sd) for  tanh  activation function and (0.5, weight_sd) for  `sigmoid`  activation function.\n",
        "\n",
        "Biases are initialized to zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0DBzNY-90s5"
      },
      "source": [
        "# Quiz Question 5\n",
        "\n",
        "In the class definition below, what should be size_a, size_b, and size_c? ONLY use the variables defined above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swHwLXOI9E7V"
      },
      "source": [
        "# LSTM \n",
        "You are making this network, please note f, i, c and o (also \"v\") in the image below:\n",
        "![alt text](http://blog.varunajayasiri.com/ml/lstm.svg)\n",
        "\n",
        "Please note that we are concatenating the old_hidden_vector and new_input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFuHhqVq6Wge"
      },
      "source": [
        "size_a = Hidden_Layer_size# write your code here\n",
        "size_b = z_size # write your code here\n",
        "size_c = X_size # write your code here\n",
        "\n",
        "class Parameters:\n",
        "    def __init__(self):\n",
        "        self.W_f = Param('W_f', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_f = Param('b_f', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_i = Param('W_i', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_i = Param('b_i', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_C = Param('W_C', np.random.randn(size_a, size_b) * weight_sd)\n",
        "        self.b_C = Param('b_C', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_o = Param('W_o', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_o = Param('b_o', np.zeros((size_a, 1)))\n",
        "\n",
        "        #For final layer to predict the next character\n",
        "        self.W_v = Param('W_v', np.random.randn(X_size, size_a) * weight_sd)\n",
        "        self.b_v = Param('b_v', np.zeros((size_c, 1)))\n",
        "        \n",
        "    def all(self):\n",
        "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
        "               self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
        "        \n",
        "parameters = Parameters()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzmfGLZt_xVs"
      },
      "source": [
        "Look at these operations which we'll be writing:\n",
        "\n",
        "**Concatenation of h and x:**\n",
        "\n",
        "$z\\:=\\:\\left[h_{t-1},\\:x\\right]$\n",
        "\n",
        "$f_t=\\sigma\\left(W_f\\cdot z\\:+\\:b_f\\:\\right)$\n",
        "\n",
        "$i_i=\\sigma\\left(W_i\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$\\overline{C_t}=\\tanh\\left(W_C\\cdot z\\:+\\:b_C\\right)$\n",
        "\n",
        "$C_t=f_t\\ast C_{t-1}+i_t\\ast \\overline{C}_t$\n",
        "\n",
        "$o_t=\\sigma\\left(W_o\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$h_t=o_t\\ast\\tanh\\left(C_t\\right)$\n",
        "\n",
        "**Logits:**\n",
        "\n",
        "$v_t=W_v\\cdot h_t+b_v$\n",
        "\n",
        "**Softmax:**\n",
        "\n",
        "$\\hat{y}=softmax\\left(v_t\\right)$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bUkseNnDott"
      },
      "source": [
        "def forward(x, h_prev, C_prev, p = parameters):\n",
        "    assert x.shape == (X_size, 1)\n",
        "    assert h_prev.shape == (Hidden_Layer_size, 1)\n",
        "    assert C_prev.shape == (Hidden_Layer_size, 1)\n",
        "    \n",
        "    z = np.row_stack((h_prev, x))\n",
        "    f = sigmoid(np.dot(p.W_f.v, z) + p.b_f.v)   # write your code here\n",
        "    i = sigmoid(np.dot(p.W_i.v, z) + p.b_i.v) # write your code here\n",
        "    C_bar = tanh(np.dot(p.W_C.v, z) + p.b_C.v)   # write your code here\n",
        "\n",
        "    C = f*C_prev + i*C_bar # write your code here\n",
        "    o = sigmoid(np.dot(p.W_o.v, z) + p.b_o.v) # write your code here\n",
        "    h = o * tanh(C) # write your code here\n",
        "\n",
        "    v =  np.dot(p.W_v.v, h) +  p.b_v.v   # write your code here\n",
        "    y = np.exp(v) / np.sum(np.exp(v)) #softmax\n",
        "\n",
        "    return z, f, i, C_bar, C, o, h, v, y"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZrDhZIjFpdI"
      },
      "source": [
        "You must finish the function above before you can attempt the questions below. \n",
        "\n",
        "# Quiz Question 6\n",
        "\n",
        "What is the output of 'print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))'?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3loq2GvMhGSA",
        "outputId": "3b9eedb7-3624-4d4b-e94a-c7ddb6a3b13e"
      },
      "source": [
        "print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV-YVl_GGiX8"
      },
      "source": [
        "# Quiz Question 6. \n",
        "\n",
        "Assuming you have fixed the forward function, run this command: \n",
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))\n",
        "\n",
        "Now, find these values:\n",
        "\n",
        "\n",
        "1.   print(z.shape)\n",
        "2.   print(np.sum(z))\n",
        "3.   print(np.sum(f))\n",
        "\n",
        "Copy and paste exact values you get in the logs into the quiz.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvKVWmTDt3H"
      },
      "source": [
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huRUmmQ2AS-L",
        "outputId": "78ec4ee2-c64d-47b3-dce1-0b727ce98725"
      },
      "source": [
        "print(z.shape)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(175, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWvnCoLKAinF",
        "outputId": "44b70070-0821-44ab-eaaa-1c02a58ee852"
      },
      "source": [
        "print(np.sum(z))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ev_yKFNNApQy",
        "outputId": "37bcaa73-b452-452f-f6a5-0fe02d7df9e8"
      },
      "source": [
        "print(np.sum(f))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeSvhkqwILsG"
      },
      "source": [
        "# Backpropagation\n",
        "\n",
        "Here we are defining the backpropagation. It's too complicated, here is the whole code. (Please note that this would work only if your earlier code is perfect)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIa1jUZiGPmF"
      },
      "source": [
        "def backward(target, dh_next, dC_next, C_prev,\n",
        "             z, f, i, C_bar, C, o, h, v, y,\n",
        "             p = parameters):\n",
        "    \n",
        "    assert z.shape == (X_size + Hidden_Layer_size, 1)\n",
        "    assert v.shape == (X_size, 1)\n",
        "    assert y.shape == (X_size, 1)\n",
        "    \n",
        "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
        "        assert param.shape == (Hidden_Layer_size, 1)\n",
        "        \n",
        "    dv = np.copy(y)\n",
        "    dv[target] -= 1\n",
        "\n",
        "    p.W_v.d += np.dot(dv, h.T)\n",
        "    p.b_v.d += dv\n",
        "\n",
        "    dh = np.dot(p.W_v.v.T, dv)        \n",
        "    dh += dh_next\n",
        "    do = dh * tanh(C)\n",
        "    do = dsigmoid(o) * do\n",
        "    p.W_o.d += np.dot(do, z.T)\n",
        "    p.b_o.d += do\n",
        "\n",
        "    dC = np.copy(dC_next)\n",
        "    dC += dh * o * dtanh(tanh(C))\n",
        "    dC_bar = dC * i\n",
        "    dC_bar = dtanh(C_bar) * dC_bar\n",
        "    p.W_C.d += np.dot(dC_bar, z.T)\n",
        "    p.b_C.d += dC_bar\n",
        "\n",
        "    di = dC * C_bar\n",
        "    di = dsigmoid(i) * di\n",
        "    p.W_i.d += np.dot(di, z.T)\n",
        "    p.b_i.d += di\n",
        "\n",
        "    df = dC * C_prev\n",
        "    df = dsigmoid(f) * df\n",
        "    p.W_f.d += np.dot(df, z.T)\n",
        "    p.b_f.d += df\n",
        "\n",
        "    dz = (np.dot(p.W_f.v.T, df)\n",
        "         + np.dot(p.W_i.v.T, di)\n",
        "         + np.dot(p.W_C.v.T, dC_bar)\n",
        "         + np.dot(p.W_o.v.T, do))\n",
        "    dh_prev = dz[:Hidden_Layer_size, :]\n",
        "    dC_prev = f * dC\n",
        "    \n",
        "    return dh_prev, dC_prev"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnc7WpRkIU5S"
      },
      "source": [
        "# Forward and Backward Combined Pass\n",
        "\n",
        "Let's first clear the gradients before each backward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJWoC3U1ITf8"
      },
      "source": [
        "def clear_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.d.fill(0)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XN93UnjIgmA"
      },
      "source": [
        "Clip gradients to mitigate exploding gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LTsublxIfFl"
      },
      "source": [
        "def clip_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        np.clip(p.d, -1, 1, out=p.d)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7XUpDTWIl_Y"
      },
      "source": [
        "Calculate and store the values in forward pass. Accumulate gradients in backward pass and clip gradients to avoid exploding gradients.\n",
        "\n",
        "input, target are list of integers, with character indexes.\n",
        "h_prev is the array of initial h at  h−1  (size H x 1)\n",
        "C_prev is the array of initial C at  C−1  (size H x 1)\n",
        "Returns loss, final  hT  and  CT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQNxjTuZIia_"
      },
      "source": [
        "def forward_backward(inputs, targets, h_prev, C_prev):\n",
        "    global paramters\n",
        "    \n",
        "    # To store the values for each time step\n",
        "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
        "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
        "    v_s, y_s =  {}, {}\n",
        "    \n",
        "    # Values at t - 1\n",
        "    h_s[-1] = np.copy(h_prev)\n",
        "    C_s[-1] = np.copy(C_prev)\n",
        "    \n",
        "    loss = 0\n",
        "    # Loop through time steps\n",
        "    assert len(inputs) == Time_steps\n",
        "    for t in range(len(inputs)):\n",
        "        x_s[t] = np.zeros((X_size, 1))\n",
        "        x_s[t][inputs[t]] = 1 # Input character\n",
        "        \n",
        "        (z_s[t], f_s[t], i_s[t],\n",
        "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
        "        v_s[t], y_s[t]) = \\\n",
        "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
        "            \n",
        "        loss += -np.log(y_s[t][targets[t], 0]) # Loss for at t\n",
        "        \n",
        "    clear_gradients()\n",
        "\n",
        "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
        "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
        "\n",
        "    for t in reversed(range(len(inputs))):\n",
        "        # Backward pass\n",
        "        dh_next, dC_next = \\\n",
        "            backward(target = targets[t], dh_next = dh_next,\n",
        "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
        "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
        "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
        "                     y = y_s[t])\n",
        "\n",
        "    clip_gradients()\n",
        "        \n",
        "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcy5u_vRItkV"
      },
      "source": [
        "# Sample the next character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8SrtJiwIsSm"
      },
      "source": [
        "def sample(h_prev, C_prev, first_char_idx, sentence_length):\n",
        "    x = np.zeros((X_size, 1))\n",
        "    x[first_char_idx] = 1\n",
        "\n",
        "    h = h_prev\n",
        "    C = C_prev\n",
        "\n",
        "    indexes = []\n",
        "    \n",
        "    for t in range(sentence_length):\n",
        "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
        "        #idx = np.random.choice(range(X_size), p=p.ravel())\n",
        "        idx = np.random.choice(range(X_size))\n",
        "        x = np.zeros((X_size, 1))\n",
        "        x[idx] = 1\n",
        "        indexes.append(idx)\n",
        "\n",
        "    return indexes"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiWFaWLNIx_L"
      },
      "source": [
        "# Training (Adagrad)\n",
        "\n",
        "Update the graph and display a sample output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENQYU-7AIw0t"
      },
      "source": [
        "def update_status(inputs, h_prev, C_prev):\n",
        "    #initialized later\n",
        "    global plot_iter, plot_loss\n",
        "    global smooth_loss\n",
        "    \n",
        "    # Get predictions for 200 letters with current model\n",
        "\n",
        "    sample_idx = sample(h_prev, C_prev, inputs[0], 200)\n",
        "    txt = ''.join(idx_to_char[idx] for idx in sample_idx)\n",
        "\n",
        "    # Clear and plot\n",
        "    plt.plot(plot_iter, plot_loss)\n",
        "    display.clear_output(wait=True)\n",
        "    plt.show()\n",
        "\n",
        "    #Print prediction and loss\n",
        "    print(\"----\\n %s \\n----\" % (txt, ))\n",
        "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACXcASJuI73a"
      },
      "source": [
        "# Update Parameters\n",
        "\n",
        "\\begin{align}\n",
        "\\theta_i &= \\theta_i - \\eta\\frac{d\\theta_i}{\\sum dw_{\\tau}^2} \\\\\n",
        "d\\theta_i &= \\frac{\\partial L}{\\partial \\theta_i}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR08TvcjI4Pf"
      },
      "source": [
        "def update_paramters(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.m += p.d * p.d # Calculate sum of gradients\n",
        "        #print(learning_rate * dparam)\n",
        "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La9vyJ6RJLFK"
      },
      "source": [
        "To delay the keyboard interrupt to prevent the training from stopping in the middle of an iteration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVDHbMb7JNGT"
      },
      "source": [
        "# Exponential average of loss\n",
        "# Initialize to a error of a random model\n",
        "smooth_loss = -np.log(1.0 / X_size) * Time_steps\n",
        "\n",
        "iteration, pointer = 0, 0\n",
        "\n",
        "# For the graph\n",
        "plot_iter = np.zeros((0))\n",
        "plot_loss = np.zeros((0))"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF6vS0VWJqsS"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "OQyNSL0iJOxH",
        "outputId": "fe3de15b-aeb6-4683-87a8-12a85dfcf6b9"
      },
      "source": [
        "iter = 50000\n",
        "while iter > 0:\n",
        "  # Reset\n",
        "  if pointer + Time_steps >= len(data) or iteration == 0:\n",
        "      g_h_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      g_C_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      pointer = 0\n",
        "\n",
        "\n",
        "  inputs = ([char_to_idx[ch] \n",
        "              for ch in data[pointer: pointer + Time_steps]])\n",
        "  targets = ([char_to_idx[ch] \n",
        "              for ch in data[pointer + 1: pointer + Time_steps + 1]])\n",
        "\n",
        "  loss, g_h_prev, g_C_prev = \\\n",
        "      forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
        "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "\n",
        "  # Print every hundred steps\n",
        "  if iteration % 100 == 0:\n",
        "      update_status(inputs, g_h_prev, g_C_prev)\n",
        "\n",
        "  update_paramters()\n",
        "\n",
        "  plot_iter = np.append(plot_iter, [iteration])\n",
        "  plot_loss = np.append(plot_loss, [loss])\n",
        "\n",
        "  pointer += Time_steps\n",
        "  iteration += 1\n",
        "  iter = iter -1"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAD1CAYAAACm0cXeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deUBU5f4G8GdYxhEdJJDB3NMwKYkkLbU0FfWi3W5mbpfU371XW65abl1Ds/LeFhXNW5alkpppC0lm3Fxwya1EXDACRRERRWSZYd+GZeb8/sAZGBgYlhmGM/N8/tE5c5bvi/LMmfe85z0SQRAEEBGRKDlYuwAiImo+hjgRkYgxxImIRIwhTkQkYgxxIiIRc2rNg6nVasTHx8PT0xOOjo6teWgiIlHSaDRQKpUYMGAAZDJZnfdbNcTj4+PxwgsvtOYhiYhswtdff41BgwbVWd6qIe7p6akvpkuXLq15aCIiUcrIyMALL7ygz8/aWjXEdV0oXbp0Qffu3Vvz0EREolZfFzQvbBIRiRhDnIhIxBjiREQixhAnIhIxhjgRkYgxxImIREw0If7AigNYtT/B2mUQEbUpognxskotNp9MtnYZRERtimhCnIiI6mKIExGJWKNuuw8JCcGFCxdQWVmJl19+Gb/88gsuXboENzc3AMDs2bMxcuRIREREYMeOHXBwcMDUqVMxZcoUixZPRGTvTIb4mTNncO3aNYSFhSE3NxfPPfcchgwZgsWLF2PUqFH69UpKSrBx40aEh4fD2dkZkydPxtixY/VBT0RE5mcyxAcPHoyHH34YAODq6orS0lJoNJo668XGxsLX1xdyuRwA4O/vj5iYGIwePdrMJRMRkY7JPnFHR0e4uLgAAMLDwzFixAg4Ojpi165dmDVrFhYtWoScnByoVCq4u7vrt3N3d4dSqbRc5URE1PipaI8cOYLw8HBs27YN8fHxcHNzg4+PD7Zs2YJPP/0UAwcONFhfEASzF0tERIYaNTrl1KlT2LRpE0JDQyGXyzF06FD4+PgAAEaPHo3ExEQoFAqoVCr9NllZWVAoFJapmoiIADQixAsLCxESEoLNmzfrL1K++uqrSE1NBQBER0fD29sbfn5+iIuLQ0FBAYqLixETE2P0UUJERGQ+JrtT9u/fj9zcXCxcuFC/bNKkSVi4cCHat28PFxcXrFq1CjKZDEuWLMHs2bMhkUgwb948/UVOIiKyDJMhPm3aNEybNq3O8ueee67OssDAQAQGBpqnMiIiMol3bBIRiRhDnIhIxBjiREQixhAnIhIxhjgRkYgxxImIRIwhTkQkYgxxIiIRY4gTEYkYQ5yISMQY4kREIsYQJyISMYY4EZGIMcSJiESMIU5EJGIMcSIiEWOIExGJGEOciEjEGOJERCLGECciEjGGOBGRiNlkiO8+n4r0/FJrl0FEZHE2F+KF6gr8K/wPvPBFtLVLISKyOJsLca226k9VYZl1CyEiagU2F+JERPaEIU5EJGIMcSIiEbPZEBesXQARUSuwvRCXWLsAIqLW49SYlUJCQnDhwgVUVlbi5Zdfhq+vL5YuXQqNRgNPT0+sXbsWUqkUERER2LFjBxwcHDB16lRMmTLF0vUTEdk1kyF+5swZXLt2DWFhYcjNzcVzzz2HoUOHIigoCOPHj8f69esRHh6OiRMnYuPGjQgPD4ezszMmT56MsWPHws3NrTXaQURkl0x2pwwePBgff/wxAMDV1RWlpaWIjo5GQEAAAGDUqFGIiopCbGwsfH19IZfLIZPJ4O/vj5iYGMtWT0Rk50yGuKOjI1xcXAAA4eHhGDFiBEpLSyGVSgEAHh4eUCqVUKlUcHd312/n7u4OpVJpobKJiAhowoXNI0eOIDw8HG+//bbBckEwPg6kvuWthsNTiMgONCrET506hU2bNiE0NBRyuRwuLi5Qq9UAgMzMTCgUCigUCqhUKv02WVlZUCgUlqm6ARKOTiEiO2IyxAsLCxESEoLNmzfrL1IOGzYMkZGRAIBDhw5h+PDh8PPzQ1xcHAoKClBcXIyYmBgMGjTIstUTEdk5k6NT9u/fj9zcXCxcuFC/bPXq1VixYgXCwsLQtWtXTJw4Ec7OzliyZAlmz54NiUSCefPmQS6XW7R4IiJ7ZzLEp02bhmnTptVZvn379jrLAgMDERgYaJ7KiIjIJNu7Y/MuXtckIntgcyHO65pEZE9sLsSJiOwJQ5yISMQY4kREIsYQJyISMZsNcavf9k9E1ApsLsQlvO+eiOyIzYU4EZE9YYgTEYkYQ5yISMQY4kREImazIc6xKURkD2wuxDk2hYjsic2FOBGRPWGIExGJGEOciEjEbDbEedc9EdkDmwtx3nVPRPbE5kKciMieMMSJiESMIU5EJGIMcSIiEbPZEBd44z0R2QGbC3EJb7wnIjticyFORGRPGOJERCLGECciEjGbDXHedk9E9qBRIZ6YmIgxY8Zg165dAIDg4GA888wzmDlzJmbOnInjx48DACIiIvD8889jypQp2L17t8WKbghvuycie+JkaoWSkhK8++67GDp0qMHyxYsXY9SoUQbrbdy4EeHh4XB2dsbkyZMxduxYuLm5mb9qIiIC0IgzcalUitDQUCgUigbXi42Nha+vL+RyOWQyGfz9/RETE2O2QomIqC6TIe7k5ASZTFZn+a5duzBr1iwsWrQIOTk5UKlUcHd317/v7u4OpVJp3mqJiMiAye4UY5599lm4ubnBx8cHW7ZswaeffoqBAwcarCPwyiIRkcU1a3TK0KFD4ePjAwAYPXo0EhMToVAooFKp9OtkZWWZ7IKxJH6EEJE9aFaIv/rqq0hNTQUAREdHw9vbG35+foiLi0NBQQGKi4sRExODQYMGmbVYIiIyZLI7JT4+HmvWrEFaWhqcnJwQGRmJGTNmYOHChWjfvj1cXFywatUqyGQyLFmyBLNnz4ZEIsG8efMgl8tbow1ERHbLZIgPGDAAO3furLP8T3/6U51lgYGBCAwMNE9lRERkks3esUlEZA9sN8R5ZZOI7IDthjgRkR1giBMRiZjoQjwjX23tEoiI2gzRhfiQVUeh0bLDm4gIEGGIA7yln4hIR5wh3qh1GPREZPvEGeIN5DNP0onInogzxBtxli0BH/FDRLZPnCHOs20iIgAiDfFLdwqsXQIRUZsgyhA/cTXL5Dq8sElE9kCUIc54JiKqIs4QZ4oTEQEQa4jzXJyICIBYQ5wZTkQEQKQhXlRWae0SiIjaBFGG+FdRN02uw7N1IrIHogxxIiKqItoQ/+VKprVLICKyOtGG+D++PI/MAj4ggojsm2hDHAA+/SXJ2iUQEVmVqEM8p7jc2iUQEVmVqEM8Ib3+ibA4OIWI7IGoQzxZVYypm6OsXQYRkdWIOsQB4OyNHGuXQERkNaIPcSIie8YQJyISMZsI8XMpOcgrMRypIvC+eyKyA40K8cTERIwZMwa7du0CAKSnp2PmzJkICgrCggULUF5eFaARERF4/vnnMWXKFOzevdtyVdcyZVMUpm8502rHIyJqK0yGeElJCd59910MHTpUv2zDhg0ICgrCN998g169eiE8PBwlJSXYuHEjvvzyS+zcuRM7duxAXl6eRYuv6UpGIV786jw0PAMnIjtiMsSlUilCQ0OhUCj0y6KjoxEQEAAAGDVqFKKiohAbGwtfX1/I5XLIZDL4+/sjJibGcpUbcfhyJsauP9GqxyQisiaTIe7k5ASZTGawrLS0FFKpFADg4eEBpVIJlUoFd3d3/Tru7u5QKpVmK7SvZ4dGrZeez/lUiMh+tPjCZn0XEM19YdFbITfr/oiIbEGzQtzFxQVqddUZb2ZmJhQKBRQKBVQqlX6drKwsgy6YlqrUNu1DQSsA2UVlZjs+EVFb1KwQHzZsGCIjIwEAhw4dwvDhw+Hn54e4uDgUFBSguLgYMTExGDRokNkK1Wi1Td7mjR/icCAu3Ww1EBG1NU6mVoiPj8eaNWuQlpYGJycnREZGYt26dQgODkZYWBi6du2KiRMnwtnZGUuWLMHs2bMhkUgwb948yOXm6wJp6pk4ABxJyMSRhEykrH7abHUQEbUlJkN8wIAB2LlzZ53l27dvr7MsMDAQgYGB5qmslkoNhw4SEdUmmjs2O7V3bva2vYP34WB8BkrKK81YERGR9YkmxD+a/kiLtn9l1wU8+HakmaohImobRBPiMmdHa5dARNTmiCbEiYioLrsL8QHvROK3JJXpFYmIRMDuQryorBIfHrpq7TKIiMzC7kIcAGJutd7sikRElmSXIQ4AqTkl1i6BiKjFRBXir46+32z7Gh5yDI+9fwTfn0812z6JiFqbqEK8QzuTN5g2SVZhGZaG/2HWfRIRtSZRhbilaJsxLwsRUVvAEAfQZ/l+VGqaPksiEZG1iSrEH/Cy3IMhMgrU0PCMnIhERlQhPqq/+R4yUduTa45h3H/5fE4iEhdRhbilXVcWIyj0DF779qK1SyEiahSGeC2nr2cjIvaOtcsgImoUhng93tobb+0SiIhMMu/Aaxuy88xNXEzNRXxaAcJeGoJeHh2QW1IOn3tdrV0aEZEeQ7wB8WkFAIBpW87ol/X2cMHEgd2wIMAbEonEWqUREQFgiDdZSnYJPjpyDR8duYbh3p3h260Tlgb2t3ZZRGSn2CfeAqeuqfDZ8evWLoOI7BhDnIhIxBjiZrD7fCqmb4mC/7uHAQDKwjL8cbvhOcvT8krhuzIS15VFrVEiEdko9ombwb9qzIQ4Zv0JJGVVBXPK6qfr3ebn2DsoVFci7Fwqlk/wsXiNRGSbRHcmfnTJU9YuoUG6AAeA0nINlIVl+NfuWM7LQnSXVivgs+NJyC+tsHYpNkF0Z+J9PTtau4RG83n7oP7v93SQYkGAN3JLytH9Hhf9ckFguJN9OZGoRMjBq0jKLML6aY9YuxzRE12Ii9WWk8nYcjIZAHDt/fHgEHOyV2WVVdM+F5VVWrkS2yC67hRb4P3mAXyw/woAIPTUDStXQ9Yy75sY9A7eZ+0ySOQY4m2AqqgMJeWVSMoqws9/3EHv4H3YeCzJ6LqCICDqeja7YWzAvj/SrV2CVfF/sHk0qzslOjoaCxYsgLe3NwCgX79+mDNnDpYuXQqNRgNPT0+sXbsWUqnUrMXaqkHvHamzbN2hq3j2ka7443Y+ent0wINdq+Zs+d8f6Xjt24tYPckX0x/r2dqlErUYuxLNq9l94o899hg2bNigf71s2TIEBQVh/PjxWL9+PcLDwxEUFGSWIu2RIFQ9qEKnnZMDZgzphZ//qJomd23kVWQUqLFwTD9rlUhEbYDZulOio6MREBAAABg1ahSioqLMtWtC1cWgrb/eQGZBGQAgu7gcHx25hgqNll0rJErN+W8744toDHrvsPmLEbFmn4knJSXhlVdeQX5+PubPn4/S0lJ994mHhweUSqXZiqT6eb95AADQuaMUqqJy7PjHYxAEASMfsNyj7IhaoiW9Kb8mqcxWR225xeWo0GqhkMssdgxLaFaI9+7dG/Pnz8f48eORmpqKWbNmQaPR6N+39Jnh0773Yl+cfV8Uqk1VVA4A+L9tZ/XLRvTzxLC+HujQzgnydk7wcpVhSB93i0+hm1dSDqmTA1ykHMFK4jHw7rQZDd1p3RY167fMy8sLEyZMAAD07NkTnTt3RlxcHNRqNWQyGTIzM6FQWO5MUOrEQTWNcTJRiZOJht+IWuOC6CP/OYx7O8kQtSzAoschomb2iUdERGDr1q0AAKVSiezsbEyaNAmRkZEAgEOHDmH48OHmq7KWmUN7WWzfti54Txx6B+9D7+B9CL9wu8F139obj/WHrjbrOOn56mZtR/ak5d/YeT2omSE+evRonDt3DkFBQZg7dy5WrlyJRYsWYe/evQgKCkJeXh4mTpxo7lr1/HveI7qvPG3R+/su48eLt7HjdAqSsoqQW1xu8P7OMzex4Rfj49UBoEKjRXRytqXLbJBWK/AXWWTM1Z0XEXsH9y3bj5vZxWbZn1g1qzulY8eO2LRpU53l27dvb3FB1HpySyqwKCzWYNnZ5QEQAOw6c1O/7OWd5xHQ3wtPeHfGh4euYmFAP/T0cMG6yKvYfDIZP817An493Orsv1BdgZJyDbxcLXehqM/y/Zg0sBvn4LBDHx9JBAAkpBeil0cHK1djPbzyRAYe++BonWWRlzIReSlT//p/sXfwRmB/XM0sBABkF5cZ3dfY9SeRUaA227em8kot1JUauMqcDZbvuZjGEG+E0JPJGPOgF+7r3DYCr6VfoK4rdWfglv0mlpZXiq2nbmDF0z5wcGh7dyrxCiE1WYVGwHv7EnD8atVF0yMJWRj33xN4a2881kZe0a+XUWDefvEZW6Px8MpDzd7+m+hb+pulWtt1ZRH+/Mkpq02/WqiuwPv7EzB9S9X9G0GhZ7Dgu4tWqaW+GNRoBfx9+1mcvZHTqvWYsuDbi9j22w38buJBL9Yi6hBP+E8glo3nQ4qt7ZvoW0jMLMLOMzex8ZjpZ46WVWqwNvIKSss1JtetqaW/3Mt/jMP8b6wTXP89nIj4tAKcSLTO/RO66exLyqp+5qevZ+On363zgVafrEI1jl1V4rVvm/ZvVPOMvrxSiwqN1qx1VbTxZwGIOsTbSx3RXupo7TKoiXZGVYX958frv2jaEHWFxuy/qG1Jak4Jlu2JQ6Ul2tiGegNqR6M5rk/3W3EAf/rvyZbvqKa7hbWhH50BUYc4APR0dzG9EllVRKzhGZ9uPulyTfN+a/u/dRDPffZbi+tqTQ21VKsV0Dt4H2ZujQYALPjuIr49ewu/p9b/9T1FVYzewftw/GpWywtoZaYGpzR18ErtpiWrLDNapamjalRFZVjyfSzUFU37xtlUog/xkQ8osGfuMGuXQQ147duLGPTeYYSdu4XDl6svkDb0O5FfWoHsouoLprXny4hPKzB4vTLikv7vvYP34aWvzrewassw1uTL6VVtOXXN8Jby+n4+fZfvx9TNVX3btT8gm3P81lbfGbducVuosabm1rXmwBX8EHMbERbuthJ9iANV48apbVMVleONH+Lw4lfn8fPdebS3nEzGr7WCK7e4HJM/Pw2/fx/CozWm6NVNK1CfL0+nGLw+VOPDwtoEQUCysvrs8GhCJt77+bL+de0zNVMnzRqtgKzCssatrN+n+U/FM/LVKDbj03m0d/ue7+SrMWrd8QbXTc8v1f/d0rcJaHXdKc38dLHEz74mmwhxAG1m2BSZlnD3zFOjFTBjazSUdwOppLwSA989jPM3cw3WLym37GO8krKKcOhShsX2v/XXG/o2SyTA7B3n8cWv1U90mrypvhk/TadGY+NBF3TmnDdnyKqjeP7z003eTlfC1YxC7PsjHYvDfq9zjeOGiS6RvRdb/6KspJHn4uoKDdLzS/XttPSHjM2E+NHFTyHhP4HWLoOaYciqo3jzxzg8+HZknff6v3XA6HJzGrP+BF7aeQFA1QfL+/suI7MFwyPVFRq881M88kuqhhPG3Kr+UGpMEFjyl95Yhl+4mQtVkfGx/qZcyShsdi1peaWY900M9lxMa7D/35ia7bD0mW5T/z3mfR2Doat+0f9bW/pyhM2EuIODBO2ljkhZ/TQWBHhbuxxqAo1WwNfRt4y+p66of4SG1sjQr/LKlo3oiL6RjdBTN/D67lj9MTafuN6kboM9MWnYEXUT65o574y+D7YRJ36NnXKgobWe//y0WS4UZxWo0Tt4n8F1j8a6klGo77ao7eyNHPi/exgF6uox9q3Zb179LaZx6x+9UnWxOVlVZLC9pdhMiNe0aGw/zq1iB0IiDUPyu7O38GtS9Tjs78+n4rqyCJUaLS7fKai9OVJzSpBXYtjXrvuFq7w7cuZAfAZWHbiCkINXam9uIFlZhDt5Vf20ujCqNPIh06ggaMKQtqbmQ337TM0pNbp84H8O4bNGDgWNv5MPAPg6unrKhpzicuyJaXiiNQANTrS2/vBV5BSXI/52vn6ZwZl4PT+EAe9E4oP9CSaPbUpTfsY1TyLOpeTe3d6yKW7Tt90nvT8ejg4SSCQSPlXcBm06YXhjUfCeOIPXS8P/qHfbOTvO4UhC3eF5umyISs7GuZQclN696JikLMKRy5lIzCqEsrAM7zzzkMF2oz88AaBqLurqgGnZL+/GY0kY91AXTHm0e4v6sheF/d7sobi5JRUIOXgVc0feb3JdXZg61Kh13tcxiErOxuDe7uhxtwZjTRFQfxgb65ZwaMTPo6isEltOJuNaZiE2vuBvML99fmkFVu1PwNvPPGhy3nvdtx2NVoBWKzR4632/FQeMbG+y1Bax6RB3cqz+orHmeV+88UNcA2uTPTEW4F+cSjY4e56yKQprJz8MAPgtKRu/JVXP2Fg7xGvSh46RX97GnJXGpeXrazySkAVlYRnKKjR4dmA3BNz9sNAxFRBZhWr8eDGturZGhN+t7BJM3xKFhWOb9vxW3Y+u5hF01xbKTdy4pNXWf76qK/mLU8lNqkfn2FUlDl/OxLOPdNMv23gsCd+dS8U9HaR4I7Bxd30/u/E3BD7UBZtmPtqk47NP3EymDe6J7X8fDADofk97K1dD1lTft7L39iVg9YGGu02MqblN7+B9+OVKVZ+wsYA19uFRW+1emLWRV7HhlyTM/CK6zroCgANx6egdvA/v77uMW9kl+veSlUV47H3DCc1yissx/5uYBo//+YnruJOvbvCbjDFCA0PxTH3YCEL9/fu6/R27Wt1VVl//eWPpjvX5cePTRBSXVeKrqJQ6NR1szigmC5+K202IA8CoBxQ4+2YAfn1jtD7QiRpiaq6T31Pz6nTr6IL60OUMs46jvlPPgzY+uTvne+ipG5jz1bmqGi5nYsPRa0bX143Tr0/zx0Pr99Dw/o28LwD6h4Dr1BwLXtsH+6s/OKu6YgRcqDU0taaaoZ9TXI7T1xueB/+9fQl4+6dLOJ6oNJrBl+7kN/qisqWnXrHp7hRjdA9BHdC1k5UrITGoL/B0faMTN9Y/qiO3pAIPvdO04ZFNneQrs0Ctv+MTqB7NM6eRd6zqLsbWdOpa8ybpqu4Tr/vemPVV3UB75z1Rz7YC/hp6xmDZ6aRsPP9o90b1f//vj/QGJ86qmbcvfBGtH7dfH90DUtTlmjoXJo9dycLfvzyH0f0V2PY30yeDgiAgv7QClRotPDq2M7l+U9nVmXhNnvJ2SFn9NP7i19XapZAI9Vm+H5ObcaOLKbrb6RsrNafE4PWtnBJcvFX/GWlts2o8WDu7qAwfHrpa70iV+giCgNzicqw/XDXCpGbm1p7HZNrmKKOjNYydrTo0IZ2OXzHspqr9xKma+7+a0XCA11b7hFt3I9IvV7Kwt8b1hnq3R9W0ETXvQDYnuzsTr23DXwciZPLD6P/WQWuXQiJT+85SazD2LNPnPmv8h0tSVpH+76ZC5vKdAkzYcAoADE5+Pj9xHd+fS0XK3f74jIIyFJVVYoCRbyESCfCPL+t+SzAW7Loz8KJGdEntqRWm07YYntXvj0vH5Ee7o0BdYfJC4zfRt/Sjkiq1Aq7V+BkB0L8HAD/E3MbEgd0Qm5oH1/aGDyvREYSqOfgtxe5DHABkzo44sngEpI6OiL2dh1ebOJ8xka2rfTG45sRbIQcNx3jHpuYZDXCg/pu3tEYWL/judyRlFeHirYbv5mxM3/QvV7IQeSkDL9+9M7e2rBp36C7/sXoU28ZjdcfIr42sO6b92Qa61SqNNc6MGOJ33a+QAwB6erigj2cHeLnK0LljO3x39ha2/5aifxQZEZlffQMMP2ngQd06C777vVHHOJ2kMrpcXaHBK7uMh3tLphXQqXkR1hIY4kY8VOOi5/THeqKsUot3akx1SkTmZcnuBp0dUTeNLm9JV+r5lFyr30jIEG+EGUN6ob3UEY/1dkdeaQXe+SkesTVuASYi+1Rq4Qc+NAZDvBEcHSSYOqiH/vVP85/E6SQVfr+dhxHenrivcwf8cTu/zhApIiJLY4g307D7O2PY/Z31r4f29UDK6qex43QK3om4hID+ClRoBZy00oNxicg+MMTNbNbQXnjOvxtcZc7QagX8HJeO9s6OKFRXYPH3sfVu5+woweRHe+Dbs8anZCUiMoYhbmYSiQSusqrxog4OEoPxtA92dYW3Qo7buSUIO5eK2U/eBydHB3SqMb501SRfrDqQgM0nkjF1UHd8f970hElEZL8Y4q2ofxdXAEAvjw5Y2sDMacvG+2DuyPvRqb0zhvTxgIvUEbdySjC0T2d8d+4WrmYU6m80+ebFxxEUWndiJCKyDwzxNkp3dj7Jv7vBct/uvgCqHlKrLCyDb/dOiH17HE5eU+JcSg66ubXHy0/1RXRyNuQyZyz/Ma7Oo686SB0xdXAPyNs5YUMjxuESUdvFEBepLp1k6NKpajKvTi7OeMavK56p0XXzeB8PAIYTDp26psTQPh4G86wvHvcAEtILsPf3NGw+kYw3J/jAvYMUy36M0z+l5PH73BFdY2KmTu2dkV9a/agsIrIehrgdGe7taXS5z72u6N9Fjn8+1RduLlIAwPOPdkdeSTm0AuDeQYro5GxculOAfzx5n367Czdz4OUqw8dHrmHGkF7QCAL8e96DSo0WeaUVWLYnDo/1docAAR/sv4LOHds1+YG8LlJHlJRbfywuUVtl9hD/4IMPEBsbC4lEguXLl+Phhx829yHIAiQSiT7AdWq+fryPh/7sXufRXu4AgLVT/AyWOzk6oHPHdgidNUi/7KURfY0et1BdAScHB8z56hwe6+2Bi6m52PZ/VdN7agUBTo4OUFdooCwsw4H4dJRVaHGfZwe4d5Ai5OBV3Ne5A14dfT+uZBRi7tcxeC3AG3kl5cjIV2OC771YGPY7vpg1CDJnR8zYymsHZHvMGuJnz57FzZs3ERYWhuvXr2P58uUICwsz5yHIxsjvjuT5es6QOu853H14gMzZET3cXep8EOydVz1Ov49nR6MPx544sPqRXNc/mICc4nLkl5bDQSLBvZ3ao0BdgfJKLZwdHVBcXom+nh0hCAI++SUJXq7tIHVyQICPF1ycHeHoIMHGY0kY0K0T/ns4EbG387FkbD8Mu78znq81La3UyQHvTRyAInUl0vJKsfXXGxjY0w0d2znhjcD+2P5bCn6IuQ2FvAl+lpoAAAfqSURBVB0K1ZVt4s4/EiezhnhUVBTGjBkDAOjbty/y8/NRVFSEjh07mvMwRM3i6CCBp7wdPOXVE/O3lzrWWU8ikeC1AG+j+5g/umr5yAcUBsuvfzABgiAgo0CNrp3a13mY7lt/ftDg9YdT/bA08AF4uVZd10jNKYFc5oSc4nJ0lrdDkboSZ5KzMcm/O7RaAbdySpBdXA6Zs4PB3D5XMwrR17OD/jpHabkGZZUauLlIUaCuwJ4LtzHuoS7QaAXczC7Bk95VH3yVGi3i0vKRlFWE68pi/MWvK25mFyNZVYwHu7qiSF0JhbwdOrRzgszZAV6uMlRqBNzTofrbWVmlBnfy1EhWFqG4XIPMfDXe35+ARWP6wdurIzYcvYZnH+mGrm4yHL+qxATfe5GQXgA3F2d07dQeKdnFOHQ5E/8c2Rdxt/Ox/nAi+neR40pGIRaP7Yec4nJ8eToFANDNrT3S8krR28MFKdkleMBLjh7uLjiSUPUovE7tnfHPkX3RQeqIk9dUOHw50+DnvXhsP1y4mYvzKTko12hbZa6W2n6q54EYLSURGvuMoUZ466238NRTT+mDPCgoCO+//z7uu6+qH/X27dsICAjA0aNH0b1794Z2RUTUJqkrNHCQSCB1qh4gUFJeifbOjo16EHVTmcpNi17YNOPnAxFRmyBzrvvtzUVqvTEiZn08m0KhgEpVPWdvVlYWPD2Nj4ggIqKWM2uIP/HEE4iMrHqix6VLl6BQKNgfTkRkQWb9DuDv74+HHnoI06dPh0QiwTvvvGPO3RMRUS1m78h5/fXXzb1LIiKqh1m7U4iIqHUxxImIRKxVx8VoNFV3pWVkZLTmYYmIREuXl7r8rK1VQ1yprHpU2QsvvNCahyUiEj2lUolevXrVWW7WOzZNUavViI+Ph6enJxwd6w6YJyIiQxqNBkqlEgMGDIBMJqvzfquGOBERmRcvbBIRiZgoHgphK3OUJyYmYu7cufjb3/6GGTNmID09HUuXLoVGo4GnpyfWrl0LqVSKiIgI7NixAw4ODpg6dSqmTJmCiooKBAcH486dO3B0dMSqVavQo0cPXLlyBStXrgQAPPDAA/j3v/9t3UbWEhISggsXLqCyshIvv/wyfH19bbrNpaWlCA4ORnZ2NsrKyjB37lz079/fptuso1ar8ec//xlz587F0KFDbbrN0dHRWLBgAby9q2a17NevH+bMmWOdNgttXHR0tPDSSy8JgiAISUlJwtSpU61cUfMUFxcLM2bMEFasWCHs3LlTEARBCA4OFvbv3y8IgiB8+OGHwtdffy0UFxcL48aNEwoKCoTS0lLh6aefFnJzc4U9e/YIK1euFARBEE6dOiUsWLBAEARBmDFjhhAbGysIgiAsXrxYOH78uBVaZ1xUVJQwZ84cQRAEIScnR3jqqadsvs379u0TtmzZIgiCINy+fVsYN26czbdZZ/369cKkSZOEH374webbfObMGeHVV181WGatNrf57pT65igXG6lUitDQUCgU1fNQR0dHIyAgAAAwatQoREVFITY2Fr6+vpDL5ZDJZPD390dMTAyioqIwduxYAMCwYcMQExOD8vJypKWl6b+Z6PbRVgwePBgff/wxAMDV1RWlpaU23+YJEybgxRdfBACkp6fDy8vL5tsMANevX0dSUhJGjhwJwPb/bxtjrTa3+RBXqVS455579K/d3d31QxXFxMnJqc6V5dLSUkilVZPse3h4QKlUQqVSwd3dXb+Orr01lzs4OEAikUClUsHV1VW/rm4fbYWjoyNcXFwAAOHh4RgxYoTNt1ln+vTpeP3117F8+XK7aPOaNWsQHBysf20PbU5KSsIrr7yCv/71r/jtt9+s1mZR9InXJNjoYJr62tWU5W31Z3PkyBGEh4dj27ZtGDdunH65Lbf5u+++Q0JCAv71r38Z1GiLbd67dy8eeeQR9OjRw+j7ttjm3r17Y/78+Rg/fjxSU1Mxa9Ysg5txWrPNbf5M3JbnKHdxcYFarQYAZGZmQqFQGG2vbrnuU7miogKCIMDT0xN5eXn6dXX7aEtOnTqFTZs2ITQ0FHK53ObbHB8fj/T0dACAj48PNBoNOnToYNNtPn78OI4ePYqpU6di9+7d+Oyzz2z+39nLywsTJkyARCJBz5490blzZ+Tn51ulzW0+xG15jvJhw4bp23bo0CEMHz4cfn5+iIuLQ0FBAYqLixETE4NBgwbhiSeewMGDBwEAx44dw+OPPw5nZ2f06dMH58+fN9hHW1FYWIiQkBBs3rwZbm5uAGy/zefPn8e2bdsAVHUFlpSU2HybP/roI/zwww/4/vvvMWXKFMydO9fm2xwREYGtW7cCqLqTMjs7G5MmTbJKm0Vxs8+6detw/vx5/Rzl/fv3t3ZJTRYfH481a9YgLS0NTk5O8PLywrp16xAcHIyysjJ07doVq1atgrOzMw4ePIitW7dCIpFgxowZ+Mtf/gKNRoMVK1YgJSUFUqkUq1evxr333oukpCS8/fbb0Gq18PPzw7Jly6zdVL2wsDB88skn+mesAsDq1auxYsUKm22zWq3Gm2++ifT0dKjVasyfPx8DBgzAG2+8YbNtrumTTz5Bt27d8OSTT9p0m4uKivD666+joKAAFRUVmD9/Pnx8fKzSZlGEOBERGdfmu1OIiKh+DHEiIhFjiBMRiRhDnIhIxBjiREQixhAnIhIxhjgRkYgxxImIROz/AeFCx+j0wxeEAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "----\n",
            " AYvnfCmJ84ygTds?ykl��. rJMEF-h3lt-fO’ ?Axbux4VUcelguv\"nx\n",
            "?0m.g“’SDa“KkSFPYz9OV'M5h“jI;r0(qbNGfJ2Blo,nhYbk 4.v(NASfcGY8T“uRHVf-HGcSWV4DvT4wr;5V;ROG7r2CU)lzcwqOC;H5O2DDt(h.cD’1D\n",
            "suOp-H18c:rY.zLbE-5'pY\"p \n",
            "----\n",
            "iter 49900, loss 6.174008\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AKpa1BGOItQ"
      },
      "source": [
        "# Quiz Question 7. \n",
        "\n",
        "Run the above code for 50000 iterations making sure that you have 100 hidden layers and time_steps is 40. What is the loss value you're seeing?"
      ]
    }
  ]
}